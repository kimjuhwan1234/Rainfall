{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:15.996074500Z",
     "start_time": "2024-06-23T05:17:12.444390Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from joblib import dump\n",
    "from scipy import stats\n",
    "from utils.scaler import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.rc('font', family='GULIM')\n",
    "warnings.filterwarnings(action='ignore')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:16.005923600Z",
     "start_time": "2024-06-23T05:17:15.997108400Z"
    }
   },
   "id": "59e4e77f713b9513",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('Database/rainfall_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('Database/rainfall_test.csv', index_col=0)\n",
    "train_col = df.columns.tolist()\n",
    "train_col.remove(train_col[-2])\n",
    "df_test.columns = train_col\n",
    "train, self_test = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:18.339715600Z",
     "start_time": "2024-06-23T05:17:16.002817700Z"
    }
   },
   "id": "54b2fb486cc3ff89",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train General Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ab97cb14a31a21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_1 = train.copy()\n",
    "mask = df_1['rainfall_train.class_interval'] == -999\n",
    "df_1 = df_1[~mask]\n",
    "\n",
    "delete_list = ['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour',\n",
    "               'rainfall_train.ef_year', 'rainfall_train.class_interval']\n",
    "df_1 = df_1.drop(columns=delete_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:18.545075600Z",
     "start_time": "2024-06-23T05:17:18.326299800Z"
    }
   },
   "id": "6413cb6705888157",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 이산형변수 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86e6060893d120d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "original_values = list(range(3, 241, 3))\n",
    "reversed_values = original_values[::-1]\n",
    "mapping_table = dict(zip(original_values, reversed_values))\n",
    "\n",
    "\n",
    "def map_value(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return mapping_table.get(x, x)\n",
    "\n",
    "\n",
    "df_2['rainfall_train.dh'] = df_2['rainfall_train.dh'].apply(map_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:19.783861700Z",
     "start_time": "2024-06-23T05:17:18.548140200Z"
    }
   },
   "id": "3c71828fcbb1aa4f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enc_dict = {}\n",
    "onehot_df = pd.DataFrame(index=df_2.index)\n",
    "for i, col in enumerate(['rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour']):\n",
    "    enc_dict[i] = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    one_hot_encoded = enc_dict[i].fit_transform(pd.DataFrame(df_2[col]))\n",
    "\n",
    "    encoded_df = pd.DataFrame(one_hot_encoded, columns=enc_dict[i].get_feature_names_out([col]), index=df_2.index)\n",
    "    onehot_df = pd.concat([onehot_df, encoded_df], axis=1)\n",
    "    df_2 = df_2.drop(columns=[col])\n",
    "df_2 = pd.concat([df_2, onehot_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:21.124689100Z",
     "start_time": "2024-06-23T05:17:19.785903800Z"
    }
   },
   "id": "f9f351f5d9783272",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 파생변수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab8913b140ce7bc6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "df_3['cum_prob']=df_3[continuous_list].sum(axis=1)\n",
    "df_3['Zero_Count'] = (df_3[continuous_list] == 0).sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:21.722871900Z",
     "start_time": "2024-06-23T05:17:21.127708800Z"
    }
   },
   "id": "9cf7ea77db1737dc",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train BoxCox변환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957ee8bc41405bac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_4=df_3.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "# continuous_list = ['rainfall_train.vv']\n",
    "\n",
    "# boxcox_dict = {}\n",
    "# for feature in continuous_list:\n",
    "#     boxcox_data, lmbda = stats.boxcox(df_3[feature] + 0.000001)\n",
    "#     boxcox_dict[feature] = lmbda\n",
    "#     df_3[feature] = boxcox_data\n",
    "    \n",
    "# df_4[continuous_list]= df_4[continuous_list].applymap(lambda x: np.log(x+1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:21.858547700Z",
     "start_time": "2024-06-23T05:17:21.724969100Z"
    }
   },
   "id": "ac0f5364e3adbd70",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pd.DataFrame(boxcox_dict.items()).to_csv('Database/boxcox_lmbda.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:21.872016600Z",
     "start_time": "2024-06-23T05:17:21.861147700Z"
    }
   },
   "id": "e57594cb3bd028f6",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 연속형변수 분포저장"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75236f11db963b51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = df_4['rainfall_train.vv']\n",
    "X = df_4.drop(columns='rainfall_train.vv')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:22.766495Z",
     "start_time": "2024-06-23T05:17:21.864838800Z"
    }
   },
   "id": "cec8003366004d60",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_norm = X_train.copy()\n",
    "X_val_norm = X_val.copy()\n",
    "\n",
    "X_train_norm.loc[:, continuous_list], scaler = standard_scale_train(X_train, continuous_list)\n",
    "X_val_norm.loc[:, continuous_list] = standard_scale_val(X_val, continuous_list, scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:23.964427600Z",
     "start_time": "2024-06-23T05:17:22.768555Z"
    }
   },
   "id": "9dd29061387dc5f3",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Database/target_scaler.joblib']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler object saved successfully!\n"
     ]
    }
   ],
   "source": [
    "y_train_norm, target_scaler = standard_scale_train(pd.DataFrame(y_train), ['rainfall_train.vv'])\n",
    "y_val_norm = standard_scale_val(pd.DataFrame(y_val), ['rainfall_train.vv'], target_scaler)\n",
    "dump(target_scaler, 'Database/target_scaler.joblib')\n",
    "print(\"Scaler object saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.035429300Z",
     "start_time": "2024-06-23T05:17:23.430412500Z"
    }
   },
   "id": "d0faa71b4aac168e",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test General Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7251cbfd6429ade"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_1 = self_test.copy()\n",
    "# df_1 = df_test.copy()\n",
    "\n",
    "mask = df_1['rainfall_train.class_interval'] == -999\n",
    "df_1 = df_1[~mask]\n",
    "\n",
    "delete_list = ['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour',\n",
    "               'rainfall_train.ef_year', 'rainfall_train.class_interval']\n",
    "df_1 = df_1.drop(columns=delete_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.036441600Z",
     "start_time": "2024-06-23T05:17:23.468321100Z"
    }
   },
   "id": "f5613864c21cec97",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 이산형변수 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b487c1d0ba45703"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "original_values = list(range(3, 241, 3))\n",
    "reversed_values = original_values[::-1]\n",
    "mapping_table = dict(zip(original_values, reversed_values))\n",
    "\n",
    "\n",
    "def map_value(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return mapping_table.get(x, x)\n",
    "\n",
    "\n",
    "df_2['rainfall_train.dh'] = df_2['rainfall_train.dh'].apply(map_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.037534400Z",
     "start_time": "2024-06-23T05:17:23.511304200Z"
    }
   },
   "id": "c5fa43ce3d24b6b0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "onehot_df = pd.DataFrame(index=df_2.index)\n",
    "for i, col in enumerate(['rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour']):\n",
    "    one_hot_encoded = enc_dict[i].transform(pd.DataFrame(df_2[col]))\n",
    "\n",
    "    encoded_df = pd.DataFrame(one_hot_encoded, columns=enc_dict[i].get_feature_names_out([col]), index=df_2.index)\n",
    "    onehot_df = pd.concat([onehot_df, encoded_df], axis=1)\n",
    "    df_2 = df_2.drop(columns=[col])\n",
    "df_2 = pd.concat([df_2, onehot_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.038532600Z",
     "start_time": "2024-06-23T05:17:23.674238400Z"
    }
   },
   "id": "a49a5d60b92f20b2",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 파생변수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c84ea44f2b8fc942"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "df_3['cum_prob']=df_3[continuous_list].sum(axis=1)\n",
    "df_3['Zero_Count'] = (df_3[continuous_list] == 0).sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.038532600Z",
     "start_time": "2024-06-23T05:17:23.845995200Z"
    }
   },
   "id": "bc2e39914583ce83",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test BoxCox변환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1140b4df5c4f1b09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "# continuous_list = ['rainfall_train.vv']\n",
    "\n",
    "# for feature in continuous_list:\n",
    "#     boxcox_data = stats.boxcox(df_3[feature] + 0.000001, lmbda=boxcox_dict[feature])\n",
    "#     df_3[feature] = boxcox_data\n",
    "\n",
    "# df_4[continuous_list]= df_4[continuous_list].applymap(lambda x: np.log(x+1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.053201800Z",
     "start_time": "2024-06-23T05:17:23.947009600Z"
    }
   },
   "id": "f8b224a93bcb3311",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 이산형변수 칼럼통일"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a7bbefecc481c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y2 = df_3['rainfall_train.vv']\n",
    "X2 = df_3.drop(columns='rainfall_train.vv')\n",
    "\n",
    "# train에만 있고 test에 없는 경우, 해당 column name으로 test에 zero columns 추가.\n",
    "X2[list(X_val_norm.columns[X_val_norm.columns.isin(X2) == False])] = 0\n",
    "\n",
    "# test에만 있고 train에는 없는 경우, 해당 column name은 제거.\n",
    "X2 = X2.drop(columns=list(X2.columns[X2.columns.isin(X_val_norm) == False]))\n",
    "X2 = X2[X_val_norm.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.071564400Z",
     "start_time": "2024-06-23T05:17:23.977850100Z"
    }
   },
   "id": "6cafd0da4f1061dc",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 연속형변수 분포통일"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9475cd7439efdc7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X2.loc[:, continuous_list] = standard_scale_val(X2, continuous_list, scaler)\n",
    "y2 = standard_scale_val(pd.DataFrame(y2), ['rainfall_train.vv'], target_scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:17:24.153241900Z",
     "start_time": "2024-06-23T05:17:24.045967200Z"
    }
   },
   "id": "7a2896378844b737",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_norm.iloc[:, 1:].to_csv('Database/total_X_train_norm.csv')\n",
    "y_train_norm.to_csv('Database/total_y_train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T05:31:34.789005700Z",
     "start_time": "2024-06-23T05:30:47.662744400Z"
    }
   },
   "id": "61ae9e08ca86fa19",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 지역별 분리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e03401e4847e15c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_norm_dict = {}\n",
    "y_train_norm_dict = {}\n",
    "\n",
    "for i, STN in enumerate(df['rainfall_train.stn4contest'].unique().tolist()):\n",
    "    train_mask = (X_train_norm['rainfall_train.stn4contest'] == STN)\n",
    "    X_train_norm_dict[STN] = X_train_norm[train_mask]\n",
    "    y_train_norm_dict[STN] = pd.DataFrame(y_train)[train_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:51:12.185471600Z",
     "start_time": "2024-06-22T14:51:09.420362200Z"
    }
   },
   "id": "4f479b75b14a6ac3",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "    X_train_norm_dict[key] = value.iloc[:, 1:]\n",
    "\n",
    "X_val_norm = X_val_norm.iloc[:, 1:]\n",
    "X2 = X2.iloc[:, 1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:51:12.368962100Z",
     "start_time": "2024-06-22T14:51:12.183130900Z"
    }
   },
   "id": "b2db31ccd08322bc",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STN001 Train set\n",
      "(62266, 57)\n",
      "(62266, 1)\n",
      "STN002 Train set\n",
      "(62189, 57)\n",
      "(62189, 1)\n",
      "STN003 Train set\n",
      "(62327, 57)\n",
      "(62327, 1)\n",
      "STN004 Train set\n",
      "(61883, 57)\n",
      "(61883, 1)\n",
      "STN005 Train set\n",
      "(61509, 57)\n",
      "(61509, 1)\n",
      "STN006 Train set\n",
      "(61729, 57)\n",
      "(61729, 1)\n",
      "STN007 Train set\n",
      "(61972, 57)\n",
      "(61972, 1)\n",
      "STN008 Train set\n",
      "(62150, 57)\n",
      "(62150, 1)\n",
      "STN009 Train set\n",
      "(62117, 57)\n",
      "(62117, 1)\n",
      "STN010 Train set\n",
      "(61638, 57)\n",
      "(61638, 1)\n",
      "STN011 Train set\n",
      "(62047, 57)\n",
      "(62047, 1)\n",
      "STN012 Train set\n",
      "(61924, 57)\n",
      "(61924, 1)\n",
      "STN013 Train set\n",
      "(61962, 57)\n",
      "(61962, 1)\n",
      "STN014 Train set\n",
      "(61837, 57)\n",
      "(61837, 1)\n",
      "STN015 Train set\n",
      "(61883, 57)\n",
      "(61883, 1)\n",
      "STN016 Train set\n",
      "(61762, 57)\n",
      "(61762, 1)\n",
      "STN017 Train set\n",
      "(61646, 57)\n",
      "(61646, 1)\n",
      "STN018 Train set\n",
      "(62005, 57)\n",
      "(62005, 1)\n",
      "STN019 Train set\n",
      "(62184, 57)\n",
      "(62184, 1)\n",
      "STN020 Train set\n",
      "(61641, 57)\n",
      "(61641, 1)\n",
      "Validation set\n",
      "(65194, 57)\n",
      "(65194,)\n",
      "Test set\n",
      "(144897, 57)\n",
      "(144897, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "    print(f'{key} Train set')\n",
    "    print(value.shape)\n",
    "    print(y_train_norm_dict[key].shape)\n",
    "\n",
    "print('Validation set')\n",
    "print(X_val_norm.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Test set')\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:51:12.374480900Z",
     "start_time": "2024-06-22T14:51:12.368962100Z"
    }
   },
   "id": "69a7a767f0ae4c0a",
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 전처리 파일저장"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bde16628edcfe83a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STN001 Train set saved!\n",
      "STN002 Train set saved!\n",
      "STN003 Train set saved!\n",
      "STN004 Train set saved!\n",
      "STN005 Train set saved!\n",
      "STN006 Train set saved!\n",
      "STN007 Train set saved!\n",
      "STN008 Train set saved!\n",
      "STN009 Train set saved!\n",
      "STN010 Train set saved!\n",
      "STN011 Train set saved!\n",
      "STN012 Train set saved!\n",
      "STN013 Train set saved!\n",
      "STN014 Train set saved!\n",
      "STN015 Train set saved!\n",
      "STN016 Train set saved!\n",
      "STN017 Train set saved!\n",
      "STN018 Train set saved!\n",
      "STN019 Train set saved!\n",
      "STN020 Train set saved!\n",
      "Validation set saved!\n",
      "Test set saved!\n"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "    value.to_csv(f'Database/train/{key}_X_train_norm.csv')\n",
    "    y_train_norm_dict[key].to_csv(f'Database/train/{key}_y_train.csv')\n",
    "    print(f'{key} Train set saved!')\n",
    "\n",
    "X_val_norm.to_csv(f'Database/val/X_val_norm.csv')\n",
    "y_val.to_csv(f'Database/val/y_val.csv')\n",
    "print('Validation set saved!')\n",
    "\n",
    "X2.to_csv(f'Database/test/X_self_test_norm.csv')\n",
    "y2.to_csv(f'Database/test/y_self_test.csv')\n",
    "print('Test set saved!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:52:03.152526200Z",
     "start_time": "2024-06-22T14:51:12.376544300Z"
    }
   },
   "id": "96d62eb21b81b0ed",
   "execution_count": 123
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
