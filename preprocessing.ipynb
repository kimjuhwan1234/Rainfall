{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:06.304256Z",
     "start_time": "2024-06-25T04:36:01.840528Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from utils.scaler import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.rc('font', family='GULIM')\n",
    "warnings.filterwarnings(action='ignore')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:07.444569Z",
     "start_time": "2024-06-25T04:36:07.434987Z"
    }
   },
   "id": "59e4e77f713b9513",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('Database/rainfall_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('Database/rainfall_test.csv')\n",
    "train_col = df.columns.tolist()\n",
    "train_col.remove(train_col[-2])\n",
    "df_test.columns = train_col\n",
    "train, self_test_df = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:11.579016Z",
     "start_time": "2024-06-25T04:36:07.458535Z"
    }
   },
   "id": "54b2fb486cc3ff89",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train General Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ab97cb14a31a21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_1 = train.copy()\n",
    "mask = df_1['rainfall_train.class_interval'] == -999\n",
    "df_1 = df_1[~mask]\n",
    "\n",
    "delete_list = ['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour',\n",
    "               'rainfall_train.ef_year', 'rainfall_train.vv']\n",
    "df_1 = df_1.drop(columns=delete_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:11.965178Z",
     "start_time": "2024-06-25T04:36:11.582154Z"
    }
   },
   "id": "6413cb6705888157",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 이산형변수 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86e6060893d120d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "original_values = list(range(3, 241, 3))\n",
    "reversed_values = original_values[::-1]\n",
    "mapping_table = dict(zip(original_values, reversed_values))\n",
    "\n",
    "\n",
    "def map_value(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return mapping_table.get(x, x)\n",
    "\n",
    "\n",
    "df_2['rainfall_train.dh'] = df_2['rainfall_train.dh'].apply(map_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:20.065253Z",
     "start_time": "2024-06-25T04:36:18.699433Z"
    }
   },
   "id": "3c71828fcbb1aa4f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enc_dict = {}\n",
    "onehot_df = pd.DataFrame(index=df_2.index)\n",
    "for i, col in enumerate(['rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour']):\n",
    "    enc_dict[i] = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    one_hot_encoded = enc_dict[i].fit_transform(pd.DataFrame(df_2[col]))\n",
    "\n",
    "    encoded_df = pd.DataFrame(one_hot_encoded, columns=enc_dict[i].get_feature_names_out([col]), index=df_2.index)\n",
    "    onehot_df = pd.concat([onehot_df, encoded_df], axis=1)\n",
    "    df_2 = df_2.drop(columns=[col])\n",
    "df_2 = pd.concat([df_2, onehot_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:25.725562Z",
     "start_time": "2024-06-25T04:36:22.279517Z"
    }
   },
   "id": "f9f351f5d9783272",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 파생변수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab8913b140ce7bc6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "df_3['cum_prob'] = df_3[continuous_list].sum(axis=1)\n",
    "df_3['Zero_Count'] = (df_3[continuous_list] == 0).sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:32.680055Z",
     "start_time": "2024-06-25T04:36:31.833664Z"
    }
   },
   "id": "9cf7ea77db1737dc",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train BoxCox변환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957ee8bc41405bac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "\n",
    "# continuous_list2 = ['rainfall_train.vv']\n",
    "# \n",
    "# boxcox_dict = {}\n",
    "# for feature in continuous_list2:\n",
    "#     boxcox_data, lmbda = stats.boxcox(df_4[feature] + 0.000001)\n",
    "#     boxcox_dict[feature] = lmbda\n",
    "#     df_4[feature] = boxcox_data\n",
    "# pd.DataFrame(boxcox_dict.items()).to_csv('Database/boxcox_lmbda.csv')\n",
    "\n",
    "# df_4[continuous_list2]= df_4[continuous_list2].applymap(lambda x: np.log(x+1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:37.562127Z",
     "start_time": "2024-06-25T04:36:37.115663Z"
    }
   },
   "id": "ac0f5364e3adbd70",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 연속형변수 분포저장"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75236f11db963b51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = df_4['rainfall_train.class_interval']\n",
    "X = df_4.drop(columns='rainfall_train.class_interval')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:43.852381Z",
     "start_time": "2024-06-25T04:36:41.713177Z"
    }
   },
   "id": "cec8003366004d60",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_norm = X_train.copy()\n",
    "X_val_norm = X_val.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09', 'cum_prob']\n",
    "\n",
    "X_train_norm.loc[:, continuous_list], scaler = standard_scale_train(X_train, continuous_list)\n",
    "X_val_norm.loc[:, continuous_list] = standard_scale_val(X_val, continuous_list, scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:36:52.544918Z",
     "start_time": "2024-06-25T04:36:49.331831Z"
    }
   },
   "id": "9dd29061387dc5f3",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test General Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7251cbfd6429ade"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "self_test = True\n",
    "\n",
    "if self_test:\n",
    "    df_1 = self_test_df.copy()\n",
    "if not self_test:\n",
    "    df_1 = df_test.copy()\n",
    "\n",
    "mask = df_1['rainfall_train.class_interval'] == -999\n",
    "df_1 = df_1[~mask]\n",
    "\n",
    "delete_list = ['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour',\n",
    "               'rainfall_train.ef_year', 'rainfall_train.vv']\n",
    "df_1 = df_1.drop(columns=delete_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:02.008449Z",
     "start_time": "2024-06-25T04:37:01.858519Z"
    }
   },
   "id": "f5613864c21cec97",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 이산형변수 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b487c1d0ba45703"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "original_values = list(range(3, 241, 3))\n",
    "reversed_values = original_values[::-1]\n",
    "mapping_table = dict(zip(original_values, reversed_values))\n",
    "\n",
    "\n",
    "def map_value(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return mapping_table.get(x, x)\n",
    "\n",
    "\n",
    "df_2['rainfall_train.dh'] = df_2['rainfall_train.dh'].apply(map_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:06.316848Z",
     "start_time": "2024-06-25T04:37:06.103225Z"
    }
   },
   "id": "c5fa43ce3d24b6b0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "onehot_df = pd.DataFrame(index=df_2.index)\n",
    "for i, col in enumerate(['rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour']):\n",
    "    one_hot_encoded = enc_dict[i].transform(pd.DataFrame(df_2[col]))\n",
    "\n",
    "    encoded_df = pd.DataFrame(one_hot_encoded, columns=enc_dict[i].get_feature_names_out([col]), index=df_2.index)\n",
    "    onehot_df = pd.concat([onehot_df, encoded_df], axis=1)\n",
    "    df_2 = df_2.drop(columns=[col])\n",
    "df_2 = pd.concat([df_2, onehot_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:09.730274Z",
     "start_time": "2024-06-25T04:37:09.343840Z"
    }
   },
   "id": "a49a5d60b92f20b2",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 파생변수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c84ea44f2b8fc942"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09']\n",
    "\n",
    "df_3['cum_prob'] = df_3[continuous_list].sum(axis=1)\n",
    "df_3['Zero_Count'] = (df_3[continuous_list] == 0).sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:12.693503Z",
     "start_time": "2024-06-25T04:37:12.551958Z"
    }
   },
   "id": "bc2e39914583ce83",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test BoxCox변환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1140b4df5c4f1b09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if self_test:\n",
    "    df_4 = df_3.copy()\n",
    "\n",
    "    # continuous_list2 = ['rainfall_train.vv']\n",
    "    # \n",
    "    # for feature in continuous_list2:\n",
    "    #     boxcox_data = stats.boxcox(df_4[feature] + 0.000001, lmbda=boxcox_dict[feature])\n",
    "    #     df_4[feature] = boxcox_data\n",
    "\n",
    "    # df_4[continuous_list2] = df_4[continuous_list2].applymap(lambda x: np.log(x + 1))\n",
    "\n",
    "if not self_test:\n",
    "    df_4 = df_3.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:15.181594Z",
     "start_time": "2024-06-25T04:37:15.076238Z"
    }
   },
   "id": "f8b224a93bcb3311",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 이산형변수 칼럼통일"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a7bbefecc481c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if self_test:\n",
    "    y2 = df_4['rainfall_train.class_interval']\n",
    "    X2 = df_4.drop(columns='rainfall_train.class_interval')\n",
    "\n",
    "    # train에만 있고 test에 없는 경우, 해당 column name으로 test에 zero columns 추가.\n",
    "    X2[list(X_val_norm.columns[X_val_norm.columns.isin(X2) == False])] = 0\n",
    "\n",
    "    # test에만 있고 train에는 없는 경우, 해당 column name은 제거.\n",
    "    X2 = X2.drop(columns=list(X2.columns[X2.columns.isin(X_val_norm) == False]))\n",
    "    X2 = X2[X_val_norm.columns]\n",
    "\n",
    "if not self_test:\n",
    "    X2 = df_4\n",
    "\n",
    "    # train에만 있고 test에 없는 경우, 해당 column name으로 test에 zero columns 추가.\n",
    "    X2[list(X_val_norm.columns[X_val_norm.columns.isin(X2) == False])] = 0\n",
    "\n",
    "    # test에만 있고 train에는 없는 경우, 해당 column name은 제거.\n",
    "    X2 = X2.drop(columns=list(X2.columns[X2.columns.isin(X_val_norm) == False]))\n",
    "    X2 = X2[X_val_norm.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:20.251162Z",
     "start_time": "2024-06-25T04:37:20.103535Z"
    }
   },
   "id": "6cafd0da4f1061dc",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test 연속형변수 분포통일"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9475cd7439efdc7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "continuous_list = [\n",
    "    'rainfall_train.v01', 'rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05',\n",
    "    'rainfall_train.v06', 'rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09', 'cum_prob']\n",
    "\n",
    "X2.loc[:, continuous_list] = standard_scale_val(X2, continuous_list, scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:23.665462Z",
     "start_time": "2024-06-25T04:37:23.545896Z"
    }
   },
   "id": "7a2896378844b737",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 지역별 분리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc96be36fd17aa9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# X_train_norm_dict = {}\n",
    "# y_train_norm_dict = {}\n",
    "# \n",
    "# for i, STN in enumerate(df['rainfall_train.stn4contest'].unique().tolist()):\n",
    "#     train_mask = (X_train_norm['rainfall_train.stn4contest'] == STN)\n",
    "#     X_train_norm_dict[STN] = X_train_norm[train_mask]\n",
    "#     y_train_norm_dict[STN] = pd.DataFrame(y_train_norm)[train_mask]\n",
    "# \n",
    "# for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "#     X_train_norm_dict[key] = value.iloc[:, 1:]\n",
    "# \n",
    "# X_val_norm = X_val_norm.iloc[:, 1:]\n",
    "# X2 = X2.iloc[:, 1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:37:26.184688Z",
     "start_time": "2024-06-25T04:37:26.176965Z"
    }
   },
   "id": "dc163c82d5dc09fc",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GMM분리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e03401e4847e15c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_norm = X_train_norm.iloc[:, 1:]\n",
    "X_val_norm = X_val_norm.iloc[:, 1:]\n",
    "X2 = X2.iloc[:, 1:]\n",
    "\n",
    "GMM = joblib.load('Database/gmm_model.pkl')\n",
    "X_train_norm = pd.concat([X_train_norm, pd.DataFrame(GMM.predict(X_train_norm), index=X_train_norm.index)], axis=1)\n",
    "\n",
    "X_train_norm_dict = {}\n",
    "y_train_norm_dict = {}\n",
    "\n",
    "for i, cluster_num in enumerate(X_train_norm[0].unique().tolist()):\n",
    "    train_mask = (X_train_norm[0] == cluster_num)\n",
    "    X_train_norm_dict[cluster_num] = X_train_norm[train_mask]\n",
    "    y_train_norm_dict[cluster_num] = pd.DataFrame(y_train)[train_mask]\n",
    "    X_train_norm_dict[cluster_num] = X_train_norm_dict[cluster_num].drop(columns=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:38:01.620192Z",
     "start_time": "2024-06-25T04:37:31.980833Z"
    }
   },
   "id": "c34a82bc7f1a9118",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train set\n",
      "(149097, 57)\n",
      "(149097, 1)\n",
      "14 Train set\n",
      "(133256, 57)\n",
      "(133256, 1)\n",
      "7 Train set\n",
      "(47078, 57)\n",
      "(47078, 1)\n",
      "10 Train set\n",
      "(187414, 57)\n",
      "(187414, 1)\n",
      "9 Train set\n",
      "(217716, 57)\n",
      "(217716, 1)\n",
      "2 Train set\n",
      "(82886, 57)\n",
      "(82886, 1)\n",
      "1 Train set\n",
      "(127385, 57)\n",
      "(127385, 1)\n",
      "4 Train set\n",
      "(143800, 57)\n",
      "(143800, 1)\n",
      "5 Train set\n",
      "(49671, 57)\n",
      "(49671, 1)\n",
      "0 Train set\n",
      "(46448, 57)\n",
      "(46448, 1)\n",
      "6 Train set\n",
      "(36450, 57)\n",
      "(36450, 1)\n",
      "12 Train set\n",
      "(5878, 57)\n",
      "(5878, 1)\n",
      "8 Train set\n",
      "(3915, 57)\n",
      "(3915, 1)\n",
      "3 Train set\n",
      "(6896, 57)\n",
      "(6896, 1)\n",
      "11 Train set\n",
      "(781, 57)\n",
      "(781, 1)\n",
      "Validation set\n",
      "(65194, 57)\n",
      "(65194,)\n",
      "Test set\n",
      "(144897, 57)\n",
      "(144897,)\n"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "    print(f'{key} Train set')\n",
    "    print(value.shape)\n",
    "    print(y_train_norm_dict[key].shape)\n",
    "\n",
    "print('Validation set')\n",
    "print(X_val_norm.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Test set')\n",
    "print(X2.shape)\n",
    "\n",
    "if self_test:\n",
    "    print(y2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:38:01.664103Z",
     "start_time": "2024-06-25T04:38:01.634726Z"
    }
   },
   "id": "69a7a767f0ae4c0a",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 전처리 파일저장"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bde16628edcfe83a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Database\\train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (key, value) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(X_train_norm_dict\u001B[38;5;241m.\u001B[39mitems()):\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mvalue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDatabase/train/GMM\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mkey\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_X_train_norm.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     y_train_norm_dict[key]\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDatabase/train/GMM\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_y_train.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGMM\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Train set saved!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    328\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    329\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    330\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    331\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    332\u001B[0m     )\n\u001B[1;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\core\\generic.py:3964\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3953\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[0;32m   3955\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[0;32m   3956\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[0;32m   3957\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3961\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[0;32m   3962\u001B[0m )\n\u001B[1;32m-> 3964\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3966\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3967\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3969\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3973\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3974\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3975\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3981\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m    993\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    995\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[0;32m    996\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[0;32m    997\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[0;32m   1017\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[0;32m    261\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m    262\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    267\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[0;32m    268\u001B[0m     )\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\io\\common.py:749\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;66;03m# Only for write methods\u001B[39;00m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m is_path:\n\u001B[1;32m--> 749\u001B[0m     \u001B[43mcheck_parent_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compression:\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzstd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    753\u001B[0m         \u001B[38;5;66;03m# compression libraries do not like an explicit text-mode\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pandas\\io\\common.py:616\u001B[0m, in \u001B[0;36mcheck_parent_directory\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    614\u001B[0m parent \u001B[38;5;241m=\u001B[39m Path(path)\u001B[38;5;241m.\u001B[39mparent\n\u001B[0;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m parent\u001B[38;5;241m.\u001B[39mis_dir():\n\u001B[1;32m--> 616\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot save file into a non-existent directory: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mOSError\u001B[0m: Cannot save file into a non-existent directory: 'Database\\train'"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(X_train_norm_dict.items()):\n",
    "    value.to_csv(f'Database/train/GMM{key}_X_train_norm.csv')\n",
    "    y_train_norm_dict[key].to_csv(f'Database/train/GMM{key}_y_train.csv')\n",
    "    print(f'GMM{key} Train set saved!')\n",
    "\n",
    "X_val_norm.to_csv(f'Database/val/X_val_norm.csv')\n",
    "y_val.to_csv(f'Database/val/y_val.csv')\n",
    "print('Validation set saved!')\n",
    "\n",
    "if self_test:\n",
    "    X2.to_csv(f'Database/test/X_self_test_norm.csv')\n",
    "    y2.to_csv(f'Database/test/y_self_test.csv')\n",
    "\n",
    "if not self_test:\n",
    "    X2.to_csv(f'Database/test/X_real_test_norm.csv')\n",
    "print('Test set saved!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:38:15.831694Z",
     "start_time": "2024-06-25T04:38:15.638087Z"
    }
   },
   "id": "96d62eb21b81b0ed",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2401041773520e99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
